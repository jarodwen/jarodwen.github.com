<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[JArod's Bits]]></title>
  <link href="http://jarodwen.github.com/atom.xml" rel="self"/>
  <link href="http://jarodwen.github.com/"/>
  <updated>2013-04-10T23:01:17-07:00</updated>
  <id>http://jarodwen.github.com/</id>
  <author>
    <name><![CDATA[JArod Wen]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Git Repository as a Backend of Knowledge Management]]></title>
    <link href="http://jarodwen.github.com/blog/2013/04/10/git-repository-as-a-backend-of-knowledge-management/"/>
    <updated>2013-04-10T22:36:00-07:00</updated>
    <id>http://jarodwen.github.com/blog/2013/04/10/git-repository-as-a-backend-of-knowledge-management</id>
    <content type="html"><![CDATA[<p>Just got some tries on <a href="http://trello.com" title="Trello">Trello</a>. It has been a very useful tool used in Stack-overflow to monitor the on-the-fly status of all developers, <strong>remotely</strong>. It is very handy to support GitHub push and pull requests (but unfortunately, no BitBucket yet).</p>

<p>The basic concepts of trello include <strong>list</strong> and <strong>card</strong>. A list is a collection of cards with some common properties, while each card can be used to track a topic. Inside of a card there is activity (as comments), and different actions (checklist, due date, move, vote, archive, etc). This structure is simple, and very close to what I am searching for as a logging and knowledge management tool: quick log, structured management, and quick search. However I just noticed that the search feature of trello is not very powerful: it cannot reach deep into the card activities.</p>

<p>And this experience makes me re-think my idea about the quick logging tool. Seems that git could be a very good backend for storing and managing the logs. There are missing pieces, like the fulltext searching support (and structured search)&#8230;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Worst Case for Quicksort]]></title>
    <link href="http://jarodwen.github.com/blog/2013/02/08/a-worst-case-for-quicksort/"/>
    <updated>2013-02-08T01:49:00-08:00</updated>
    <id>http://jarodwen.github.com/blog/2013/02/08/a-worst-case-for-quicksort</id>
    <content type="html"><![CDATA[<p>It is well-known that quicksort is the best-practice sorting algorithm with the average lg(n) complexity. But, it may reach the worst case using O(n<sup>2</sup> ). Here is the question: what is the worst case?</p>

<p>Before further discussion, the quicksort algorithm should be specified first. There are so many quicksort implementations with different optimization strategies. But for this post, I will only focus on the <strong>three-way-partition quicksort</strong>. A full description of this algorithm can be found from Dr. Donald&#8217;s book, and (in my opinion) an easier version of the instruction can be found from his student Robert Sedgewick (a google search for &#8220;Quicksort is optimal&#8221;).</p>

<p>The basic idea of quicksort is a divide-n-conquer procedure. The main process includes:</p>

<ol>
<li>Pick a pivot;</li>
<li>Partition the records based on the value of pivot: records larger (or smaller, of your choice) than the pivot will be on the left side partition, while the other records are on the right;</li>
<li>Do 1 and 2 on the two partitions.</li>
</ol>


<p>The recursion can be terminated if there is only 1 record left in the partition (2 is also a possible stop sign, depending on your implementation). The three-way-partition quicksort algorithm brings the benefit to handle duplicates: if there is duplicates having the same value as the pivot, they would be moved to the middle (so they are not in either partitions so no need to be processed recursively).</p>

<p>The context is enough (hopefully). Go back to the question: how can we find a dataset that has to be sorted using O(n<sup>2</sup> ) time in quicksort?</p>

<p>Is the sorted or reverse-sorted the worst case? Some texts provide this as a hint to understand the worst case of quicksort, however this would not happen for the three-way-partition. If you already know the three-way-partition algorithm (or you have read the related chapters from the two references above), you will see:</p>

<ul>
<li>For a sorted data set, a single scan is enough to finish the sort.</li>
<li>For a reverse-sorted data set, for the first partition from the middle, the swaps in a quicksort will reverse the order in a single round (5 4 |3| 2 1 becomes 1 2 |3| 4 5 by swapping 5 and 1, 4 and 2). So actually a reverse-sorted data set can be finished faster than a random dataset:)</li>
</ul>


<p>From the idea of quicksort, it is clear that the worst case should be a dataset which <strong>the pivots of different levels are chosen with skew</strong>. Here &#8220;skew&#8221; means the partition is not a half-half cut. To find a dataset with skewed partition on the first level is easy, but after the first level, it is hard to guarantee that the skew happens in the produced partition.</p>

<p>And now, here comes the example. Consider the following dataset:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>11, 13, 15, 17, 19, 1, 3, 5, 7, 9, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20</span></code></pre></td></tr></table></div></figure>


<p>Let&#8217;s start the quicksort. First, we pick the middle for the pivot, 2. After the swapping, we get the following partitions:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>1, 2, | 15, 17, 19, 11, 3, 5, 7, 9, 20, 4, 6, 8, 10, 12, 14, 16, 18, 13</span></code></pre></td></tr></table></div></figure>


<p>For the left side, there are only two numbers so it can be terminated. For the right side, the interesting thing is that the next pivot is 4. Do the quicksort again, we have:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>3, 4, | 19, 11, 15, 5, 7, 9, 20, 13, 6, 8, 10, 12, 14, 16, 18, 17</span></code></pre></td></tr></table></div></figure>


<p>I think you see the point now; the pivots are chosen as 2, 4, 6, 8, &#8230;, so each round of the quicksort will only have 2 numbers done. So totally for this dataset we need 10 levels. Each level we need to scan the whole number list. Then we get a O(n<sup>2</sup> )~</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bit 0]]></title>
    <link href="http://jarodwen.github.com/blog/2012/12/19/bit-0/"/>
    <updated>2012-12-19T06:09:00-08:00</updated>
    <id>http://jarodwen.github.com/blog/2012/12/19/bit-0</id>
    <content type="html"><![CDATA[<p>I should admit that I love trying new things. I can count all my old blogs using more than 2 bits, and now there is another one. The problem is that more blogs means less motivation to update any of them. But I do not want to throw away any of them, as any post is a small piece of the past.</p>

<p>Again, <a href="http://octopress.org">Octopress</a> seems to be a very handy tool for blogging. More geeky features can be customized with little efforts. It would be interesting to probe it for a while. Sounds attractive to me&#8230; So let me try again :).</p>
]]></content>
  </entry>
  
</feed>
